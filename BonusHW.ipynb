{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovn6dxAcR19M"
      },
      "source": [
        "# Bonus Quest\n",
        "\n",
        "**Difficulty:** A\n",
        "\n",
        "**Description:** Students are in a tough spot after changing the grading formula for assignments and now fear taking the exam without a 3.5 GPA. The system gives players a chance to raise their score by completing this bonus quest. This is your Solo Leveling. Survive at all costs. Good luck!\n",
        "\n",
        "**Goal:** Complete the bonus assignment created by Andrei and corrected by Max.\n",
        "\n",
        "**Deliverables:**\n",
        "- Jupyter Notebook (ipynb) file with solution and all cell outputs\n",
        "- CSV file with model predictions\n",
        "- Both files uploaded to GitHub repository\n",
        "\n",
        "**Reward:**\n",
        "- Bonus points for the Assignment part.\n",
        "- Title “The one who overcomes the difficulties of fate.”\n",
        "- +1000 EXP in mastering sklearn\n",
        "- Skill Upgrade «ML Engineering Lv.2»\n",
        "- Special Item: [???]\n",
        "\n",
        "---\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "As a dataset, use Russian news from Balto-Slavic Natural Language Processing 2019 (helsinki.fi). Entities of interest: PER, ORG, LOC, EVT, PRO (see Guidelines_20190122.pdf (helsinki.fi)).\n",
        "\n",
        "It is sufficient to use 9 documents about Brexit from the sample provided by the organizers.\n",
        "\n",
        "## Approach\n",
        "\n",
        "This assignment combines traditional ML methods (using scikit-learn) with modern LLM-based approaches (DeepSeek) for comparison. You will:\n",
        "1. Formulate the problem as a machine learning task\n",
        "2. Prepare features and split data appropriately\n",
        "3. Train and compare multiple models using scikit-learn\n",
        "4. Evaluate models using proper train/test splits\n",
        "5. Compare ML model performance with DeepSeek responses\n",
        "6. Analyze results in terms of course concepts (bias-variance tradeoff, overfitting, generalization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFS64IbBSBQ0"
      },
      "source": [
        "Example of one document:\n",
        "\n",
        "ru-10\n",
        "\n",
        "ru\n",
        "\n",
        "2018-09-20\n",
        "\n",
        "https://rg.ru/2018/09/20/tereza-mej-rasschityvaet-usidet-v-sedle-do-zaversheniia-procedury-brexit.html\n",
        "\n",
        "Theresa May expects to stay in the saddle until the completion of the Brexit procedure\n",
        "However, according to British media reports, at the upcoming Conservative Party conference at the end of September, May's opponents will give her a serious fight, from which it is not certain that she will emerge victorious. The bookmakers' favorite as a possible replacement for the current prime minister, former British Foreign Secretary Boris Johnson intends to deliver an alternative report that will leave no stone unturned from the government's views on the conditions of \"Brexit\". From Johnson's point of view, \"London has wrapped the British constitution in a suicide belt and handed the detonator to Michel Barnier (Brussels' chief Brexit negotiator. - Ed.)\". It is with this metaphor that the head of the British government will have to fight at the conference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anYOHrNESnyC"
      },
      "source": [
        "### Task 1\n",
        "**Problem Formulation & ML Perspective**\n",
        "\n",
        "Describe the task from both NLP and ML perspectives:\n",
        "- What kind of machine learning problem is this? (classification, sequence labeling, etc.)\n",
        "- How can this be formulated as a supervised learning problem?\n",
        "- What classical ML methods exist for solving it? (e.g., logistic regression, naive Bayes, SVM with text features)\n",
        "- How can it be solved using modern LLMs like DeepSeek?\n",
        "- What are the assumptions of different model classes? (e.g., linear models vs. more complex approaches)\n",
        "- How is model quality typically evaluated in this task? What metrics are appropriate and why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. С точки зрения NLP - распознавание именованных сущностей в тексте (найти слова, отнасящиеся к данным категориям), с точки зрения ML - классификация (проссматриваем слова и относим их к каким-то классам, нас будут интересовать перечисленные в условии).\n",
        "2. На вход подаем токены, на выходе ожидаем метку класса. Размеченные данные уже есть в датасете. Можем обучать методом обучения с учителем.\n",
        "3. SVM хорошо подойдет, он показывает хорошую точность, жертвуя \"вероятностной\" интерпретации выходных данных, которая в данном случаем нам не нужна. Выбираем самый подходящий класс, не смотря на подходящесть других.\n",
        "4. Задаем модели запрос: \"Найди в тексте все упоминания личностей (PER), организаций (ORG)...\". Для большей точности можно дать пару примеров.\n",
        "5. Линейные модели предполагают линейную разделимость классов, более сложная LLM модель может улавливать более сложные случаи, операясь на контекст.\n",
        "6. f1-score может хорошо подойти, ведь в этом задании может наблюдаться эффект сильной несбалансированности классов (маленькая выборка, определенная тематика, да и вообще такие классы довольно сильно отличаются по частотности вхождения в тексты), а f1 метрика это сглаживает."
      ],
      "metadata": {
        "id": "QB4R-HVIA7kB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHJOa5nDSrRd"
      },
      "source": [
        "### Task 2\n",
        "**Data Loading & Preparation**\n",
        "\n",
        "Implement reading the dataset into a pandas DataFrame with mandatory columns \"document_id\", \"document_text\", \"entity\", \"gold_answer\".\n",
        "\n",
        "Then prepare the data for ML:\n",
        "- Create features from text (e.g., using CountVectorizer or TfidfVectorizer from sklearn)\n",
        "- Encode entity labels appropriately\n",
        "- Display the head of the dataframe and show basic statistics about the dataset\n",
        "- Discuss any data quality issues or preprocessing steps needed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpcF_B5KSx1v"
      },
      "source": [
        "### Task 3\n",
        "**Train/Test Split & Data Splitting Strategy**\n",
        "\n",
        "Split your data appropriately for machine learning:\n",
        "- Implement train/test split (or train/validation/test if appropriate)\n",
        "- Justify your splitting strategy (random split, stratified split, etc.)\n",
        "- Explain why this split is appropriate for this problem\n",
        "- Display the sizes of each split\n",
        "- Also write a function that takes a dataframe row as input and outputs the input message text for DeepSeek (for later comparison)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcFpDmRUS4eH"
      },
      "source": [
        "### Task 4\n",
        "**Model Training with scikit-learn**\n",
        "\n",
        "Train at least 2-3 different models using scikit-learn on the training set:\n",
        "- Use appropriate models for text classification (e.g., LogisticRegression, MultinomialNB, LinearSVC)\n",
        "- Train each model using the sklearn API correctly\n",
        "- Explain why you chose these particular models\n",
        "- Discuss the assumptions each model makes and whether they are appropriate for this problem\n",
        "- Save the trained models\n",
        "\n",
        "**Also (for comparison):** Get DeepSeek responses for all documents. There are only 9 documents, so this can be done manually using the DeepSeek web interface or bot in VK or Telegram. Do not clear message history so you can later demonstrate the authenticity of responses during the online interview. Add DeepSeek responses to the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRZSH3TdTG-i"
      },
      "source": [
        "### Task 5\n",
        "**Model Evaluation & Metrics**\n",
        "\n",
        "Evaluate your trained models on the test set:\n",
        "- Use appropriate sklearn metrics (accuracy, precision, recall, F1-score, confusion matrix)\n",
        "- Compare performance across different models\n",
        "- Implement your own algorithm for calculating a custom metric score_fn(gold: str, pred: str) → float if needed (you can only use numpy, scipy, pandas libraries). Write unit tests. Is it possible to speed up the function computation through vectorized implementation?\n",
        "- Explain which metrics you chose and why they are appropriate for this problem\n",
        "- Discuss the limitations of the metrics you're using\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY8WJ7gBTNq7"
      },
      "source": [
        "### Task 6\n",
        "**Model Comparison & Visualization**\n",
        "\n",
        "Compare all models (your sklearn models and DeepSeek):\n",
        "- Calculate metrics for each model\n",
        "- Aggregate the results a) by each entity type, b) by each document\n",
        "- Visualize the results on graphs (e.g., bar charts comparing models, confusion matrices)\n",
        "- Which model performs best? Why might this be?\n",
        "- Compare train vs test performance for your sklearn models. Are there signs of overfitting or underfitting?\n",
        "- What conclusions can be drawn about model selection?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpl708OvTcZu"
      },
      "source": [
        "### Task 7\n",
        "**Bias-Variance Analysis**\n",
        "\n",
        "Analyze your models in terms of course concepts:\n",
        "- Is there a dependence of metrics on document length? Build graphs to answer the question.\n",
        "- Analyze the bias-variance tradeoff: Are your models showing high bias (underfitting) or high variance (overfitting)?\n",
        "- Compare train vs test performance. What does this tell you about generalization?\n",
        "- If you observe overfitting, what could you do to reduce it? (e.g., regularization, simpler models)\n",
        "- If you observe underfitting, what could you do? (e.g., more features, more complex models)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkWma7-9TfFe"
      },
      "source": [
        "### Task 8\n",
        "**Error Analysis & Model Interpretation**\n",
        "\n",
        "Conduct detailed error analysis:\n",
        "- When do the models answer correctly more often, and when do they make mistakes?\n",
        "- Analyze errors by entity type, document characteristics, etc.\n",
        "- Interpret your models: Can you explain why certain predictions were made? (e.g., for linear models, look at feature weights)\n",
        "- Compare errors between sklearn models and DeepSeek. What patterns do you see?\n",
        "- Propose concrete ways to improve the metrics based on your analysis\n",
        "- Discuss the tradeoffs between model complexity, interpretability, and performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN8lQEedTkxo"
      },
      "source": [
        "### Task 9\n",
        "**Conclusions & Reflection**\n",
        "\n",
        "Make conclusions about the entire research:\n",
        "- Summarize your findings: Which approach worked best and why?\n",
        "- Connect your results to course concepts: bias-variance tradeoff, overfitting, generalization, model assumptions\n",
        "- What are the limitations of your approach? What assumptions did you make?\n",
        "- What would you do differently if you had more time or data?\n",
        "- Write what you learned and what new things you tried\n",
        "- Reflect on the end-to-end ML workflow: from problem formulation to evaluation\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}